{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baf4642-0e7e-4d66-b8db-d84e438b23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 19:35:18.925245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ.pop(\"TF_USE_LEGACY_KERAS\", None)  # ensure we are not forcing tf_keras\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# file paths\n",
    "input_path = '../../data/simulated/simulated_1d/'\n",
    "model_path = './model_1d_tuned/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# feature parameters\n",
    "ndim = 1\n",
    "feature_grid_range = [-4, 4]\n",
    "feature_grid_nbins = 100\n",
    "\n",
    "\n",
    "def extract_features(\n",
    "    data,\n",
    "    feature_grid_range=feature_grid_range,\n",
    "    feature_grid_nbins=feature_grid_nbins\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts normalized histogram features from standardized 1D or 2D data.\n",
    "    \n",
    "    Arguments:\n",
    "        data: 1D or 2D numpy array\n",
    "              - if 1D: shape (n_samples,)\n",
    "              - if 2D: shape (n_samples, 2)\n",
    "    Returns:\n",
    "        features: 1D or 2D feature vector (normalized histogram)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.asarray(data).squeeze()\n",
    "    \n",
    "    # 1d case\n",
    "    if data.ndim == 1:\n",
    "        \n",
    "        # check for standardized data\n",
    "        assert np.abs(0 - data.mean()) < 1e-2, 'Error: data not standardized'\n",
    "        assert np.abs(1 - data.std()) < 1e-2, 'Error: data not standardized'\n",
    "        \n",
    "        # histogram\n",
    "        features = np.histogram(\n",
    "            data,\n",
    "            bins=np.linspace(\n",
    "                feature_grid_range[0],\n",
    "                feature_grid_range[1],\n",
    "                feature_grid_nbins+1\n",
    "            ),\n",
    "            density=True\n",
    "        )[0]\n",
    "    \n",
    "    # 2d case\n",
    "    elif data.ndim == 2 and data.shape[1] == 2:\n",
    "        # check for standardized data\n",
    "        assert np.allclose(data.mean(axis=0), 0, atol=1e-2), 'Error: data not standardized'\n",
    "        assert np.allclose(data.std(axis=0), 1, atol=1e-2), 'Error: data not standardized'\n",
    "        \n",
    "        # 2d histogram\n",
    "        features = np.histogram2d(\n",
    "            data[:, 0], data[:, 1],\n",
    "            bins=np.linspace(\n",
    "                feature_grid_range[0],\n",
    "                feature_grid_range[1],\n",
    "                feature_grid_nbins+1\n",
    "            ),\n",
    "            density=True\n",
    "        )[0]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Input must be standardized 1D array or 2D array with 2 features\")\n",
    "    \n",
    "    # normalize features to [0,1]\n",
    "    features = (features - features.min()) / (features.max() - features.min())\n",
    "    \n",
    "    return features\n",
    "    \n",
    "\n",
    "# load data\n",
    "x_train = pickle.load(open(input_path+'/train/input_data.pkl', 'rb'))\n",
    "y_train = pickle.load(open(input_path+'/train/target_data.pkl', 'rb'))\n",
    "sizes_train = pickle.load(open(input_path+'/train/sizes.pkl', 'rb'))\n",
    "x_val = pickle.load(open(input_path+'/val/input_data.pkl', 'rb'))\n",
    "y_val = pickle.load(open(input_path+'/val/target_data.pkl', 'rb'))\n",
    "sizes_val = pickle.load(open(input_path+'/val/sizes.pkl', 'rb'))\n",
    "\n",
    "# prepare features\n",
    "x_train = [extract_features(i) for i in x_train]\n",
    "x_train = np.array(x_train).squeeze()\n",
    "x_val = [extract_features(i) for i in x_val]\n",
    "x_val = np.array(x_val).squeeze()\n",
    "\n",
    "# standardize outputs\n",
    "scaler = RobustScaler()\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_val = scaler.transform(y_val)\n",
    "with open(f\"{model_path}/scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "# add channel axis\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_val = x_val[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0792be44-8266-4e07-bd00-e44942c7b4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 100, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652329b3-c536-4f79-b636-48f401ccd9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27344a5-e8b3-48d1-ae3b-721e81c71bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 21s]\n",
      "val_mae: 0.29546013474464417\n",
      "\n",
      "Best val_mae So Far: 0.28164488077163696\n",
      "Total elapsed time: 00h 18m 15s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"Define CNN regressor architecture with tunable hyperparameters.\"\"\"\n",
    "\n",
    "    # Input shape selection\n",
    "    if ndim == 1:\n",
    "        input_dim = (feature_grid_nbins, 1)\n",
    "        output_dim = 3\n",
    "        conv_layer = tf.keras.layers.Conv1D\n",
    "        pooling_layer = tf.keras.layers.MaxPooling1D\n",
    "    else:\n",
    "        input_dim = (feature_grid_nbins, feature_grid_nbins, 1)\n",
    "        output_dim = 6\n",
    "        conv_layer = tf.keras.layers.Conv2D\n",
    "        pooling_layer = tf.keras.layers.MaxPooling2D\n",
    "\n",
    "    # Tunable hyperparameters\n",
    "    num_conv_blocks = hp.Choice('num_conv_blocks', [2, 3])  # number of conv+pool blocks\n",
    "    kernel_size = hp.Choice('kernel_size', [5, 9, 13])      # large kernels\n",
    "    pool_size = hp.Choice('pool_size', [2, 3])              # moderate pooling\n",
    "    dense_units = hp.Choice('dense_units', [32, 64])        # size of dense layer\n",
    "    dropout_rate = 0.2                                      # regularization\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 5e-3, 1e-3, 5e-4])\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd_momentum'])\n",
    "    loss_choice = hp.Choice('loss', ['mse', 'mae', 'huber'])\n",
    "\n",
    "    # Model body\n",
    "    inputs = tf.keras.layers.Input(shape=input_dim)\n",
    "    x = inputs\n",
    "    for i in range(num_conv_blocks):\n",
    "        filters = 32 if i == 0 else 64\n",
    "        x = conv_layer(filters, kernel_size=kernel_size,\n",
    "                       activation='relu', padding='same')(x)\n",
    "        x = pooling_layer(pool_size=pool_size, padding='same')(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(dense_units, activation='relu')(x)\n",
    "    if dropout_rate > 0.0:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    outputs = tf.keras.layers.Dense(output_dim, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Optimizer choice (SGD with momentum)\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_choice,\n",
    "        metrics=['mae', 'mse']  # keep val_mae as objective\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_mae',          # minimize validation val MAE\n",
    "    max_trials=50,                # total configurations to try\n",
    "    num_initial_points=10,        # random warmup before Bayesian starts\n",
    "    directory=model_path,\n",
    "    project_name='rinet_v2_1d_bayesian_search'\n",
    ")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=model_path + 'model.weights.h5',\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c257ce4-f042-40f4-8a2e-63dedbcb055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/rinet/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model val MAE: 0.28164488077163696\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "_, val_mae, val_mse = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Best model val MAE:\", val_mae)\n",
    "model.save_weights(model_path + 'model.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c79f12c-c869-4656-b3d0-ab2d0d808833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path + 'best_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9b71b5-05dc-4a6b-83ca-d9076df2d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/rinet/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(model_path + 'best_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f09a58c-0086-4184-8c0f-cf4556e2ba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model val MAE: 0.28164488077163696\n"
     ]
    }
   ],
   "source": [
    "_, val_mae, val_mse = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Best model val MAE:\", val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd93cb0-0899-45be-9a78-f15c26c891fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_conv_blocks</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>pool_size</th>\n",
       "      <th>dense_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.281645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.287160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.287859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.287903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.288181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.288243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.288700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.289370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.289696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.290206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.291871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.292213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.292213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.292365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.292382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.292730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.293170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.293238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.294223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.294319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.294458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.295460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.295603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.297098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.297111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.298421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.300335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.301180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.303025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.305695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.306355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.307736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.309921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.311650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.325582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>adam</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.326827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>adam</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.327201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>adam</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.332951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd_momentum</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.345788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>sgd_momentum</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.346934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd_momentum</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.351195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd_momentum</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.355992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_conv_blocks  kernel_size  pool_size  dense_units  learning_rate  \\\n",
       "20                3            9          2           32         0.0005   \n",
       "28                3            9          2           32         0.0005   \n",
       "40                3            9          2           32         0.0005   \n",
       "18                3            9          2           32         0.0005   \n",
       "29                3            9          2           32         0.0005   \n",
       "17                3            9          2           32         0.0005   \n",
       "39                3            9          2           32         0.0005   \n",
       "43                3            9          2           32         0.0005   \n",
       "21                3            9          2           32         0.0005   \n",
       "31                3            9          2           32         0.0005   \n",
       "19                3            9          2           32         0.0005   \n",
       "34                3            9          2           32         0.0005   \n",
       "25                3            9          2           32         0.0005   \n",
       "26                3            9          2           32         0.0005   \n",
       "33                3            9          2           32         0.0005   \n",
       "47                3            9          2           32         0.0005   \n",
       "15                3           13          2           32         0.0005   \n",
       "27                3            9          2           32         0.0005   \n",
       "38                3            9          2           32         0.0005   \n",
       "37                3            9          2           32         0.0005   \n",
       "44                3            9          2           32         0.0005   \n",
       "22                3            9          2           32         0.0005   \n",
       "23                3            9          2           32         0.0005   \n",
       "45                3            9          2           32         0.0005   \n",
       "24                3            9          2           32         0.0005   \n",
       "42                3            9          2           32         0.0005   \n",
       "48                3            9          2           32         0.0005   \n",
       "36                3            9          2           32         0.0005   \n",
       "7                 3            9          2           32         0.0010   \n",
       "49                3            9          2           32         0.0005   \n",
       "41                3            9          2           32         0.0005   \n",
       "32                3            9          2           32         0.0005   \n",
       "46                3            9          2           32         0.0005   \n",
       "30                3            9          2           32         0.0005   \n",
       "35                3            9          2           32         0.0005   \n",
       "16                2           13          2           32         0.0005   \n",
       "13                3            9          2           32         0.0010   \n",
       "11                2            9          2           32         0.0010   \n",
       "9                 2            5          3           64         0.0010   \n",
       "14                2            9          2           32         0.0010   \n",
       "2                 2            5          3           64         0.0010   \n",
       "5                 2           13          2           32         0.0050   \n",
       "0                 3            5          2           64         0.0050   \n",
       "8                 2            9          2           32         0.0050   \n",
       "1                 3           13          2           64         0.0100   \n",
       "6                 2            9          3           32         0.0100   \n",
       "12                3            5          3           64         0.0005   \n",
       "3                 2            5          3           32         0.0050   \n",
       "10                3            5          2           32         0.0005   \n",
       "4                 2            9          3           32         0.0005   \n",
       "\n",
       "       optimizer   loss   val_mae  \n",
       "20          adam    mae  0.281645  \n",
       "28          adam    mae  0.287160  \n",
       "40          adam    mae  0.287859  \n",
       "18          adam    mae  0.287903  \n",
       "29          adam    mae  0.288181  \n",
       "17          adam    mae  0.288243  \n",
       "39          adam    mae  0.288700  \n",
       "43          adam    mae  0.289370  \n",
       "21          adam    mae  0.289696  \n",
       "31          adam    mae  0.290206  \n",
       "19          adam    mae  0.291017  \n",
       "34          adam    mae  0.291044  \n",
       "25          adam    mae  0.291162  \n",
       "26          adam    mae  0.291204  \n",
       "33          adam    mae  0.291484  \n",
       "47          adam    mae  0.291570  \n",
       "15          adam    mae  0.291640  \n",
       "27          adam    mae  0.291767  \n",
       "38          adam    mae  0.291871  \n",
       "37          adam    mae  0.292213  \n",
       "44          adam    mae  0.292213  \n",
       "22          adam    mae  0.292365  \n",
       "23          adam    mae  0.292382  \n",
       "45          adam    mae  0.292730  \n",
       "24          adam    mae  0.293170  \n",
       "42          adam    mae  0.293238  \n",
       "48          adam    mae  0.294223  \n",
       "36          adam    mae  0.294319  \n",
       "7           adam  huber  0.294458  \n",
       "49          adam    mae  0.295460  \n",
       "41          adam    mae  0.295603  \n",
       "32          adam    mae  0.297098  \n",
       "46          adam    mae  0.297111  \n",
       "30          adam    mae  0.298421  \n",
       "35          adam    mae  0.300335  \n",
       "16          adam  huber  0.301180  \n",
       "13          adam  huber  0.303025  \n",
       "11          adam    mae  0.305695  \n",
       "9           adam    mse  0.306355  \n",
       "14          adam  huber  0.307736  \n",
       "2           adam  huber  0.309921  \n",
       "5           adam    mae  0.311650  \n",
       "0           adam    mae  0.325582  \n",
       "8           adam    mae  0.326827  \n",
       "1           adam    mse  0.327201  \n",
       "6           adam    mse  0.332951  \n",
       "12  sgd_momentum    mse  0.345788  \n",
       "3   sgd_momentum  huber  0.346934  \n",
       "10  sgd_momentum    mae  0.351195  \n",
       "4   sgd_momentum    mse  0.355992  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for trial_id, trial in tuner.oracle.trials.items():\n",
    "    row = trial.hyperparameters.values.copy()\n",
    "    row['val_mae'] = trial.score\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(by='val_mae', ascending=True)\n",
    "df.to_csv('./model_1d_tuning_summary.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f97a46-0770-4d07-8c53-4b721296ddb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_rinet",
   "language": "python",
   "name": "conda_rinet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
