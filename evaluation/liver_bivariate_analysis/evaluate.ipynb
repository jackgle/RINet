{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfea198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from shapely) (1.26.4)\n",
      "Downloading shapely-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "Successfully installed shapely-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f9fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers as lib\n",
    "from rinet.metrics import bhattacharyya_gaussian_distance\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "pred_path = '../benchmarking/predictions/rinet_v2_liver_2d_ornone.pkl'\n",
    "data_path = '../../data/liver/'\n",
    "ri_sources = ['abim', 'leeds']\n",
    "ris_path = {}\n",
    "for source in ri_sources:\n",
    "    ris_path[source] = f\"{data_path}/established_ri/{source}_ris.json\"\n",
    "\n",
    "\n",
    "def load_p_y(pair, gender):\n",
    "    \"\"\"Load predicted and directly estimated reference regions\"\"\"\n",
    "    \n",
    "    # filter to given analyte pair and gender\n",
    "    idx = metadata[(metadata['analyte_pair'] == str(pair)) & (metadata['gender'] == gender)].index.to_numpy()[0]\n",
    "    p = predictions[idx]\n",
    "    y = targets[idx]\n",
    "\n",
    "    # convert from dictionary\n",
    "    p = [p['mean'], p['covariance'], p['reference_fraction']]\n",
    "\n",
    "    # get region vertices\n",
    "    region_p = lib.get_ellipse_vertices(p[0], p[1])\n",
    "    region_y = lib.get_ellipse_vertices(y[0], y[1])\n",
    "\n",
    "    return region_p, region_y, p, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f79be8-67f3-43be-a839-211bec7a4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "predictions = pickle.load(open(pred_path, 'rb'))[1]\n",
    "targets = pickle.load(open(f\"{data_path}/outlier_removal_none/2d/targets.pkl\", 'rb'))\n",
    "metadata = pd.read_csv(f\"{data_path}/outlier_removal_none/2d/metadata.csv\", index_col=0)\n",
    "\n",
    "df = pd.read_csv(f\"{data_path}/liver_preprocessed.csv\")\n",
    "analytes = df.columns[3:]  # list of analytes\n",
    "analytes = analytes.drop(['cholesterol', 'cholinesterase', 'alkaline phosphatase'])  # remove 3 analytes\n",
    "log_analytes = list(analytes)  # transform all analytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef21f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "\t ('alanine aminotransferase', 'albumin')\n",
      "\t ('alanine aminotransferase', 'aspartate aminotransferase')\n",
      "\t ('alanine aminotransferase', 'bilirubin')\n",
      "\t ('alanine aminotransferase', 'creatinine')\n",
      "\t ('alanine aminotransferase', 'gamma-glutamyl transferase')\n",
      "\t ('alanine aminotransferase', 'total protein')\n",
      "\t ('albumin', 'aspartate aminotransferase')\n",
      "\t ('albumin', 'bilirubin')\n",
      "\t ('albumin', 'creatinine')\n",
      "\t ('albumin', 'gamma-glutamyl transferase')\n",
      "\t ('albumin', 'total protein')\n",
      "\t ('aspartate aminotransferase', 'bilirubin')\n",
      "\t ('aspartate aminotransferase', 'creatinine')\n",
      "\t ('aspartate aminotransferase', 'gamma-glutamyl transferase')\n",
      "\t ('aspartate aminotransferase', 'total protein')\n",
      "\t ('bilirubin', 'creatinine')\n",
      "\t ('bilirubin', 'gamma-glutamyl transferase')\n",
      "\t ('bilirubin', 'total protein')\n",
      "\t ('creatinine', 'gamma-glutamyl transferase')\n",
      "\t ('creatinine', 'total protein')\n",
      "\t ('gamma-glutamyl transferase', 'total protein')\n",
      "F\n",
      "\t ('alanine aminotransferase', 'albumin')\n",
      "\t ('alanine aminotransferase', 'aspartate aminotransferase')\n",
      "\t ('alanine aminotransferase', 'bilirubin')\n",
      "\t ('alanine aminotransferase', 'creatinine')\n",
      "\t ('alanine aminotransferase', 'gamma-glutamyl transferase')\n",
      "\t ('alanine aminotransferase', 'total protein')\n",
      "\t ('albumin', 'aspartate aminotransferase')\n",
      "\t ('albumin', 'bilirubin')\n",
      "\t ('albumin', 'creatinine')\n",
      "\t ('albumin', 'gamma-glutamyl transferase')\n",
      "\t ('albumin', 'total protein')\n",
      "\t ('aspartate aminotransferase', 'bilirubin')\n",
      "\t ('aspartate aminotransferase', 'creatinine')\n",
      "\t ('aspartate aminotransferase', 'gamma-glutamyl transferase')\n",
      "\t ('aspartate aminotransferase', 'total protein')\n",
      "\t ('bilirubin', 'creatinine')\n",
      "\t ('bilirubin', 'gamma-glutamyl transferase')\n",
      "\t ('bilirubin', 'total protein')\n",
      "\t ('creatinine', 'gamma-glutamyl transferase')\n",
      "\t ('creatinine', 'total protein')\n",
      "\t ('gamma-glutamyl transferase', 'total protein')\n"
     ]
    }
   ],
   "source": [
    "# run prediction\n",
    "unique_pairs = sorted(list(set(itertools.combinations(analytes, 2))))  # get all pairs of analytes\n",
    "results = []\n",
    "for gender in ['M', 'F']:  # loop genders\n",
    "    \n",
    "    print(gender)\n",
    "    \n",
    "    for pair in unique_pairs:  # loop pairs\n",
    "        \n",
    "        print('\\t', pair)\n",
    "        pair = list(pair)\n",
    "\n",
    "        # get estimated regions\n",
    "        region_p, region_y, gaus_p, gaus_y = load_p_y(tuple(pair), gender)\n",
    "        \n",
    "        # get established RIs\n",
    "        region_ri = {}\n",
    "        for source in ri_sources:\n",
    "            ris_dict = json.load(open(ris_path[source], 'r'))  # ris\n",
    "            region_ri[source] = lib.get_ri_vertices(ris_dict, pair, gender)\n",
    "\n",
    "        # inverse transform regions\n",
    "        for c in range(2):\n",
    "            if pair[c] in log_analytes:\n",
    "                region_p[:, c] = np.exp(region_p[:, c])\n",
    "                region_y[:, c] = np.exp(region_y[:, c])\n",
    "            \n",
    "        # get full dataset not transformed\n",
    "        # outlier removal?\n",
    "        data, labels = lib.get_data(\n",
    "            df, pair, gender, log_analytes,\n",
    "            outlier_removal=False,\n",
    "            transform=False\n",
    "        )\n",
    "\n",
    "        ref_frac = len([i for i in labels if i == 'reference' ])/len(labels)\n",
    "        \n",
    "        # bhattacharyya coefficient\n",
    "        bd = bhattacharyya_gaussian_distance(\n",
    "            gaus_p[0], gaus_p[1], \n",
    "            gaus_y[0], gaus_y[1]\n",
    "        )\n",
    "        bc = np.exp(-bd)\n",
    "        \n",
    "        # get IoU between directly estimated and predicted regions\n",
    "        iou_model = lib.iou(region_p, region_y)\n",
    "        iou_ri = {}\n",
    "        for source in ri_sources:\n",
    "            iou_ri[source] = lib.iou(region_ri[source], region_y)        \n",
    "        \n",
    "        # estimate precision recall fscore and support of predicted positive/negative patients vs labels\n",
    "        labels_nn = lib.predict_labels(data, region_p)\n",
    "        assert len(labels_nn) == len(data), 'Error: number of labels != len dataset (model)'\n",
    "        labels_ri = {}\n",
    "        for source in ri_sources:\n",
    "            labels_ri[source] = lib.predict_labels(data, region_ri[source])\n",
    "            assert len(labels_ri[source]) == len(data), 'Error: number of labels != len dataset (RIs)'\n",
    "        labels_direct = lib.predict_labels(data, region_y)\n",
    "        assert len(labels_direct) == len(data), 'Error: number of labels != len dataset (direct estimate)'\n",
    "        \n",
    "        # run evaluation only using confirmed normal and HCV (not just \"abnormal\")\n",
    "        idx = np.array([i != 'abnormal' for i in labels])\n",
    "        labels_target = labels[idx]\n",
    "        labels_target = labels_target != 'reference'\n",
    "        scores_nn = precision_recall_fscore_support(labels_target, labels_nn[idx])\n",
    "        scores_ri = {}\n",
    "        for source in ri_sources:\n",
    "            scores_ri[source] = precision_recall_fscore_support(labels_target, labels_ri[source][idx])\n",
    "        scores_direct = precision_recall_fscore_support(labels_target, labels_direct[idx])\n",
    "        \n",
    "        # get standardized vertices for standardized areas\n",
    "        region_p_standard = (region_p-data.mean(axis=0))/data.std(axis=0)\n",
    "        region_ri_standard = {}\n",
    "        for source in ri_sources:\n",
    "            region_ri_standard[source] = (region_ri[source]-data.mean(axis=0))/data.std(axis=0)\n",
    "        region_y_standard = (region_y-data.mean(axis=0))/data.std(axis=0)\n",
    "        \n",
    "        # compile results\n",
    "        result = {\n",
    "            'pair': pair,\n",
    "            'gender': gender,\n",
    "            'labels': labels,\n",
    "            'model': {\n",
    "                'volume': ConvexHull(region_p).volume,\n",
    "                'volume_standard': ConvexHull(region_p_standard).volume,\n",
    "                'coverage': len(np.where(~labels_nn[idx] & ~labels_target)[0])/len(np.where(~labels_target)[0]),\n",
    "                'bhattacharyya_coefficient': bc,\n",
    "                'iou': iou_model,\n",
    "                'vertices': region_p,\n",
    "                'precision': scores_nn[0],\n",
    "                'recall': scores_nn[1],\n",
    "                'f1score': scores_nn[2],\n",
    "                'support': scores_nn[3],\n",
    "                'reference_frac': gaus_p[2],\n",
    "                'reference_frac_error': np.abs(gaus_p[2] - ref_frac),\n",
    "                'labels': labels_nn,\n",
    "                'model': gaus_p\n",
    "            },\n",
    "            'direct': {\n",
    "                'volume': ConvexHull(region_y).volume,\n",
    "                'volume_standard': ConvexHull(region_y_standard).volume,\n",
    "                'coverage': len(np.where(~labels_direct[idx] & ~labels_target)[0])/len(np.where(~labels_target)[0]),\n",
    "                'bhattacharyya_coefficient': 1,\n",
    "                'iou': 1,\n",
    "                'vertices': region_y,\n",
    "                'precision': scores_direct[0],\n",
    "                'recall': scores_direct[1],\n",
    "                'f1score': scores_direct[2],\n",
    "                'support': scores_direct[3],\n",
    "                'labels': labels_direct,\n",
    "                'model': gaus_y\n",
    "            }\n",
    "        }\n",
    "        result['model']['coverage_area_ratio'] = result['model']['coverage'] / result['model']['volume_standard']\n",
    "        result['direct']['coverage_area_ratio'] = result['direct']['coverage'] / result['model']['volume_standard']\n",
    "        \n",
    "        for source in ri_sources:\n",
    "            result['ri_'+source] = {\n",
    "                'volume': ConvexHull(region_ri[source]).volume,\n",
    "                'volume_standard': ConvexHull(region_ri_standard[source]).volume,\n",
    "                'coverage': len(np.where(~labels_ri[source][idx] & ~labels_target)[0])/len(np.where(~labels_target)[0]),\n",
    "                'bhattacharyya_coefficient': None,\n",
    "                'iou': iou_ri[source],\n",
    "                'vertices': region_ri[source],\n",
    "                'precision': scores_ri[source][0],\n",
    "                'recall': scores_ri[source][1],\n",
    "                'f1score': scores_ri[source][2],\n",
    "                'support': scores_ri[source][3],\n",
    "                'labels': labels_ri[source],\n",
    "                'model': None\n",
    "            }\n",
    "            result['ri_'+source]['coverage_area_ratio'] = result['ri_'+source]['coverage'] / result['ri_'+source]['volume_standard']\n",
    "\n",
    "        results.append(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa56aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Model: 0.9379361514398011\n",
      "Average Coverage RI (abim): 0.8231588536593749\n",
      "Average Coverage RI (leeds): 0.9157270432035812\n",
      "Average Coverage Direct: 0.9524544798267426\n",
      "\n",
      "\n",
      "Average Standard Area Model: 2.659774652190825\n",
      "Average Standard Area RI (abim): 4.0462364352722044\n",
      "Average Standard Area RI (leeds): 3.2604401730613852\n",
      "Average Standard Area Direct: 2.6904340999865544\n",
      "\n",
      "\n",
      "Average C-A-Ratio Model: 0.5725806010522303\n",
      "Average C-A-Ratio RI (abim): 0.532090291137621\n",
      "Average C-A-Ratio RI (leeds): 0.4175499468324306\n",
      "Average C-A-Ratio Direct: 0.5831257371590538\n",
      "\n",
      "\n",
      "Average Sensitivity Model: 0.6664502164502165\n",
      "Average Sensitivity RI (abim): 0.6841125541125541\n",
      "Average Sensitivity RI (leeds): 0.6066666666666667\n",
      "Average Sensitivity Direct: 0.6660173160173161\n",
      "\n",
      "\n",
      "Average IoU Model: 0.8289675972892687\n",
      "Average IOU RI (abim): 0.486620509628178\n",
      "Average IOU RI (leeds): 0.5353433770247437\n",
      "Average BC Model: 0.9908830746853072\n",
      "Average Ref Frac Model: 0.7010845\n",
      "Average Ref Frac Error Model: 0.06129801929801483\n"
     ]
    }
   ],
   "source": [
    "# can also check this is the same as recall[0]\n",
    "print('Average Coverage Model: '+str(np.mean([i['model']['coverage'] for i in results])))\n",
    "for source in ri_sources:\n",
    "    print(f\"Average Coverage RI ({source}): {str(np.mean([i['ri_'+source]['coverage'] for i in results]))}\")\n",
    "print('Average Coverage Direct: '+str(np.mean([i['direct']['coverage'] for i in results])))\n",
    "print('\\n')\n",
    "\n",
    "print('Average Standard Area Model: '+str(np.mean([i['model']['volume_standard'] for i in results])))\n",
    "for source in ri_sources:\n",
    "    print(f\"Average Standard Area RI ({source}): {str(np.mean([i['ri_'+source]['volume_standard'] for i in results]))}\")\n",
    "print('Average Standard Area Direct: '+str(np.mean([i['direct']['volume_standard'] for i in results])))\n",
    "print('\\n')\n",
    "\n",
    "print('Average C-A-Ratio Model: '+str(np.mean([i['model']['coverage_area_ratio'] for i in results])))\n",
    "for source in ri_sources:\n",
    "    print(f\"Average C-A-Ratio RI ({source}): {str(np.mean([i['ri_'+source]['coverage_area_ratio'] for i in results]))}\")\n",
    "print('Average C-A-Ratio Direct: '+str(np.mean([i['direct']['coverage_area_ratio'] for i in results])))\n",
    "print('\\n')\n",
    "\n",
    "print('Average Sensitivity Model: '+str(np.mean([i['model']['recall'][1] for i in results])))\n",
    "for source in ri_sources:\n",
    "    print(f\"Average Sensitivity RI ({source}): {str(np.mean([i['ri_'+source]['recall'][1] for i in results]))}\")\n",
    "print('Average Sensitivity Direct: '+str(np.mean([i['direct']['recall'][1] for i in results])))\n",
    "print('\\n')\n",
    "\n",
    "print('Average IoU Model: '+str(np.mean([i['model']['iou'] for i in results])))\n",
    "for source in ri_sources:\n",
    "    print(f\"Average IOU RI ({source}): {str(np.mean([i['ri_'+source]['iou'] for i in results]))}\")\n",
    "print('Average BC Model: '+str(np.mean([i['model']['bhattacharyya_coefficient'] for i in results])))\n",
    "print('Average Ref Frac Model: '+str(np.mean([i['model']['reference_frac'] for i in results])))\n",
    "print('Average Ref Frac Error Model: '+str(np.mean([i['model']['reference_frac_error'] for i in results])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82043016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std. Dev. Ref Frac Model: 0.057553567\n"
     ]
    }
   ],
   "source": [
    "print('Std. Dev. Ref Frac Model: '+str(np.std([i['model']['reference_frac'] for i in results])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4422825b-4662-4824-9e87-370529ec2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_pickle(results, './results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af54a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
