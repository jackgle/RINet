{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb59a45-998d-4cd4-9b67-f84b670136e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/tf_p311/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/ec2-user/SageMaker/tf_p311/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from rinet.models import RINetV1Pipeline, RINetV2Pipeline, GMMPipeline, RefineRPipeline, ReflimRPipeline\n",
    "import helpers as lib\n",
    "\n",
    "# ---- prepare indirect estimation pipelines -------\n",
    "models = {\n",
    "    'rinet_v1': RINetV1Pipeline(),\n",
    "    'rinet_v1_log': RINetV1Pipeline(),\n",
    "    'rinet_v2': {\n",
    "        '1d': RINetV2Pipeline(),\n",
    "        '2d': RINetV2Pipeline(ndim=2)\n",
    "    },\n",
    "    'gmm': GMMPipeline(),\n",
    "    'reflimR': ReflimRPipeline(),\n",
    "    'refineR': RefineRPipeline()\n",
    "}\n",
    "trained_model_path_v1 = '../../modeling/v1/model/'\n",
    "trained_model_path_v2_1d = '../../modeling/v2/model_1d_tuned/'\n",
    "trained_model_path_v2_2d = '../../modeling/v2/model_2d_tuned/'\n",
    "models['rinet_v1'].load(trained_model_path_v1)  # load the trained model weights for rinet\n",
    "models['rinet_v1_log'].load(trained_model_path_v1)  # load the trained model weights for rinet\n",
    "models['rinet_v2']['1d'].load(trained_model_path_v2_1d, model_file='best_model.keras')\n",
    "models['rinet_v2']['2d'].load(trained_model_path_v2_2d, model_file='best_model.keras')\n",
    "\n",
    "data_dir = '../../data/'\n",
    "datasets = {\n",
    "    'liver_1d_ornone': f\"{data_dir}/liver/outlier_removal_none/1d/samples.pkl\",\n",
    "    'liver_2d_ornone': f\"{data_dir}/liver/outlier_removal_none/2d/samples.pkl\",\n",
    "    'liver_1d_orsample': f\"{data_dir}/liver/outlier_removal_samplewise/1d/samples.pkl\",\n",
    "    'liver_2d_orsample': f\"{data_dir}/liver/outlier_removal_samplewise/2d/samples.pkl\",\n",
    "    'liver_1d_orpanel': f\"{data_dir}/liver/outlier_removal_panelwise/1d/samples.pkl\",\n",
    "    'liver_2d_orpanel': f\"{data_dir}/liver/outlier_removal_panelwise/2d/samples.pkl\",\n",
    "    'simulated_1d': f\"{data_dir}/simulated/simulated_1d/test/original_data.pkl\",\n",
    "    'simulated_2d': f\"{data_dir}/simulated/simulated_2d/test/original_data.pkl\"\n",
    "}\n",
    "\n",
    "dataset_adapters = {\n",
    "    \"liver_1d_ornone\": lib.Liver1DAdapter(),\n",
    "    \"liver_1d_orsample\": lib.Liver1DAdapter(),\n",
    "    \"liver_1d_orpanel\": lib.Liver1DAdapter(),\n",
    "    \"simulated_1d\": lib.Simulated1DAdapter(),\n",
    "    \"liver_2d_ornone\": lib.Liver2DAdapter(),\n",
    "    \"liver_2d_orsample\": lib.Liver2DAdapter(),\n",
    "    \"liver_2d_orpanel\": lib.Liver2DAdapter(),\n",
    "    \"simulated_2d\": lib.Simulated2DAdapter(),\n",
    "}\n",
    "\n",
    "\n",
    "def run_or_load_model(out_dir, model_key, dataset_key, data):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = f\"{out_dir}/{model_key}_{dataset_key}.pkl\"\n",
    "\n",
    "    adapter = dataset_adapters.get(dataset_key,lib.BaseDatasetAdapter())\n",
    "    model = models[model_key]\n",
    "\n",
    "    # handle rinet_v2 special sub-models\n",
    "    if model_key == \"rinet_v2\":\n",
    "        if \"1d\" in dataset_key:\n",
    "            model = model[\"1d\"]\n",
    "        elif \"2d\" in dataset_key:\n",
    "            model = model[\"2d\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected dataset key for rinet_v2: {dataset_key}\")\n",
    "\n",
    "    # check compatibility\n",
    "    if not adapter.is_compatible(model_key):\n",
    "        raise ValueError(f\"Model {model_key} incompatible with {dataset_key}\")\n",
    "\n",
    "    # load cache if exists\n",
    "    if os.path.exists(out_path):\n",
    "        print(\"\\t\\tFound prediction file\")\n",
    "        return lib.load_pickle(out_path)\n",
    "\n",
    "    # prepare input\n",
    "    data_in = [adapter.transform_in(i, model_key) for i in data]\n",
    "    kwargs = getattr(adapter, \"extra_kwargs\", lambda key: {})(model_key)\n",
    "\n",
    "    # run model\n",
    "    p_full = model.predict(data_in, **kwargs)\n",
    "    if '1d' in dataset_key:\n",
    "        p_ri = [\n",
    "            adapter.transform_out(lib.out_to_ri(model_key, i), j, model_key)\n",
    "            if i is not None else np.nan\n",
    "            for i, j in zip(p_full, data)\n",
    "        ]\n",
    "    else:\n",
    "        p_ri = None\n",
    "\n",
    "    # save cache\n",
    "    lib.save_pickle([p_ri, p_full], out_path)\n",
    "    print(\"\\t\\tSaved prediction file\")\n",
    "\n",
    "    return p_ri, p_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768232c4-b620-4708-812e-53f51124e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... liver_1d_ornone\n",
      "\tRunning... rinet_v1\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v1_log\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "\tRunning... reflimR\n",
      "\t\tFound prediction file\n",
      "\tRunning... refineR\n",
      "\t\tFound prediction file\n",
      "Processing... liver_2d_ornone\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "Processing... liver_1d_orsample\n",
      "\tRunning... rinet_v1\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v1_log\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "\tRunning... reflimR\n",
      "\t\tFound prediction file\n",
      "\tRunning... refineR\n",
      "\t\tFound prediction file\n",
      "Processing... liver_2d_orsample\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "Processing... liver_1d_orpanel\n",
      "\tRunning... rinet_v1\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v1_log\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "\tRunning... reflimR\n",
      "\t\tFound prediction file\n",
      "\tRunning... refineR\n",
      "\t\tFound prediction file\n",
      "Processing... liver_2d_orpanel\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "Processing... simulated_1d\n",
      "\tRunning... rinet_v1\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v1_log\n",
      "\t\tFound prediction file\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n",
      "\tRunning... reflimR\n",
      "\t\tFound prediction file\n",
      "\tRunning... refineR\n",
      "\t\tFound prediction file\n",
      "Processing... simulated_2d\n",
      "\tRunning... rinet_v2\n",
      "\t\tSaved prediction file\n",
      "\tRunning... gmm\n",
      "\t\tFound prediction file\n"
     ]
    }
   ],
   "source": [
    "out_dir = 'predictions'\n",
    "\n",
    "p = {}\n",
    "for d in datasets:\n",
    "    data = lib.load_pickle(datasets[d])\n",
    "    p[d] = {}\n",
    "    print(f\"Processing... {d}\")\n",
    "    for m in models:\n",
    "        if dataset_adapters[d].is_compatible(m):\n",
    "            print(f\"\\tRunning... {m}\")\n",
    "            p[d][m] = run_or_load_model(out_dir, m, d, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b85d5-79c0-43bd-8c0a-db458ec3e053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
